---
title: 'Video Generation'
api: 'POST https://llm.ai-nebula.com/v1/video/generations'
---

## Introduction

The video generation API supports text-to-video, image-to-video, video-to-video, and more. Through a unified API interface, you can call multiple mainstream video generation models including Sora 2, Veo, Ali Wanxiang, and Doubao Seedance.

**Important Note**: Video generation is an asynchronous task. You need to first submit a task to get a task ID, then poll the task status until it succeeds.

## Supported Models and Features

| Model Series | Model Name | Supported Features |
|-------------|------------|-------------------|
| **Sora 2** | `sora-2` | Text-to-video, Image-to-video, Video-to-video (Remix mode) |
| **Google Veo** | `veo-3.0-fast-generate-001` | Text-to-video (first frame mode) |
| | `veo-3.1-fast-generate-preview` | Text-to-video (first frame mode, first/last frame mode) |
| **Ali Wanxiang** | `wan2.5-t2v-preview` | Text-to-video |
| | `wan2.5-i2v-preview` | Image-to-video (first frame mode) |
| **Doubao Seedance** | `doubao-seedance-1-0-lite-t2v-250428` | Text-to-video |
| | `doubao-seedance-1-0-lite-i2v-250428` | Image-to-video (first frame mode, first/last frame mode, reference image mode) |
| | `doubao-seedance-1-0-pro-250528` | Text-to-video (first frame mode) |

**Feature Description**:
- **Text-to-Video (T2V)**: Generate video from text prompts only
- **Image-to-Video (I2V)**: Generate video based on reference images
  - **First Frame Mode**: Use first frame image as starting scene
  - **First/Last Frame Mode**: Use first and last frame images to control video start and end scenes
  - **Reference Image Mode**: Use reference images as style reference (only supported by some models)
- **Video-to-Video (Remix)**: Regenerate based on existing video (only Sora 2 supports)

## Authentication

<ParamField header="Authorization" type="string" required>
  Bearer Token, e.g. `Bearer sk-xxxxxxxxxx`
</ParamField>

## API Endpoints

### Submit Video Task

**POST** `/v1/video/generations`

Submit a video generation task and return a task ID for subsequent queries.

### Query Video Task

**GET** `/v1/video/generations/{task_id}`

Query the status and results of a video generation task by task ID.

#### Path Parameters

<ParamField path="task_id" type="string" required>
  Video generation task ID returned by the submit task interface
</ParamField>

#### Response Examples

**Task Status Description**:

| Status | Description | Suggested Action |
|--------|-------------|------------------|
| `queued` | Task queued, waiting for processing | Continue polling |
| `in_progress` | Task being processed | Continue polling |
| `succeeded` | Task completed successfully | Download video |
| `failed` | Task failed | View error reason |

**Response Example (Queued)**:
```json
{
  "task_id": "video_69095b4ce0048190893a01510c0c98b0",
  "status": "queued",
  "format": "mp4"
}
```

**Response Example (In Progress)**:
```json
{
  "task_id": "video_69095b4ce0048190893a01510c0c98b0",
  "status": "in_progress",
  "format": "mp4"
}
```

**Response Example (Completed)**:
```json
{
  "task_id": "video_69095b4ce0048190893a01510c0c98b0",
  "status": "succeeded",
  "format": "mp4"
}
```

**Response Example (Failed)**:
```json
{
  "task_id": "video_69095b4ce0048190893a01510c0c98b0",
  "status": "failed",
  "format": "mp4",
  "error": {
    "code": 400,
    "message": "Prompt contains inappropriate content"
  }
}
```

#### Usage Example

```bash
curl -X GET "https://llm.ai-nebula.com/v1/video/generations/video_69095b4ce0048190893a01510c0c98b0" \
  -H "Authorization: Bearer sk-xxxxxxxxxx"
```

### Download Video

**GET** `/v1/video/generations/download?id={videoId}`

Download completed video files (Sora 2 only).

#### Query Parameters

<ParamField query="id" type="string" required>
  Video ID returned by the query task interface (task_id)
</ParamField>

#### Response Example

```json
{
  "success": true,
  "generation_id": "video_69095b4ce0048190893a01510c0c98b0",
  "task_id": "video_69095b4ce0048190893a01510c0c98b0",
  "format": "mp4",
  "size": 15728640,
  "base64": "AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAB...",
  "data_url": "data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAB..."
}
```

**Response Field Description**:

| Field | Type | Description |
|-------|------|-------------|
| `success` | boolean | Success status |
| `generation_id` | string | Generation ID (same as videoId) |
| `task_id` | string | Task ID |
| `format` | string | Video format (fixed as `"mp4"`) |
| `size` | number | Video file size (bytes) |
| `base64` | string | Base64 encoded video data |
| `data_url` | string | Data URL format video data, can be used directly in frontend `<video>` tags |

#### Usage Example

```bash
curl -X GET "https://llm.ai-nebula.com/v1/video/generations/download?id=video_69095b4ce0048190893a01510c0c98b0" \
  -H "Authorization: Bearer sk-xxxxxxxxxx"
```

## Submit Video Task

**POST** `/v1/video/generations`

Submit a video generation task and return a task ID for subsequent queries.

#### Usage Examples

<Tabs>
  <Tab title="Sora 2">
    **1. Text-to-Video (Basic Example)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "sora-2",
        "prompt": "A cute little cat playing in the garden, sunny and warm",
        "seconds": "4",
        "size": "720x1280"
      }'
    ```
    
    **2. Text-to-Video (Landscape, 8 seconds)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "sora-2",
        "prompt": "A cute little cat playing in the garden, sunny and warm",
        "seconds": "8",
        "size": "1280x720"
      }'
    ```
    
    **3. Image-to-Video (First Frame Mode)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "sora-2",
        "prompt": "A cute little cat playing in the garden, sunny and warm",
        "seconds": "4",
        "size": "720x1280",
        "input_reference": "data:image/png;base64,iVBORw0KGgoAAxxxx..."
      }'
    ```
    
    **4. Remix Mode (Video-to-Video)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "sora-2",
        "prompt": "Change the video to a night scene with stars",
        "seconds": "4",
        "size": "720x1280",
        "remix_from_video_id": "video_69095b4ce0048190893a01510c0c98b0"
      }'
    ```
  </Tab>
  
  <Tab title="Veo">
    **1. Text-to-Video (Basic Example)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "veo-3.1-fast-generate-preview",
        "prompt": "Aerial view of a sci-fi city at dawn, sunlight piercing through clouds",
        "durationSeconds": 8,
        "aspectRatio": "16:9",
        "resolution": "1080p",
        "fps": 24,
        "generateAudio": true,
        "personGeneration": "allow_all",
        "addWatermark": false
      }'
    ```
    
    **2. Text-to-Video (Portrait, with Random Seed)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "veo-3.1-fast-generate-preview",
        "prompt": "Aerial view of a sci-fi city at dawn, sunlight piercing through clouds",
        "durationSeconds": 6,
        "aspectRatio": "9:16",
        "resolution": "720p",
        "fps": 30,
        "generateAudio": false,
        "personGeneration": "allow_adult",
        "addWatermark": true,
        "seed": 12345,
        "sampleCount": 2
      }'
    ```
    
    **3. Image-to-Video (First Frame Mode)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "veo-3.1-fast-generate-preview",
        "prompt": "Generate video based on this image, scene gradually unfolds",
        "durationSeconds": 8,
        "aspectRatio": "16:9",
        "resolution": "1080p",
        "fps": 24,
        "image": "data:image/png;base64,iVBORw0KGgoAAxxxx...",
        "generateAudio": true,
        "personGeneration": "dont_allow",
        "addWatermark": false
      }'
    ```
    
    **4. Image-to-Video (First/Last Frame Mode, only veo-3.1 supports)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "veo-3.1-fast-generate-preview",
        "prompt": "Transition from first image to second image",
        "durationSeconds": 8,
        "aspectRatio": "16:9",
        "resolution": "1080p",
        "fps": 24,
        "image": "data:image/png;base64,iVBORw0KGgoAAxxxx...",
        "lastFrame": "data:image/png;base64,iVBORw0KGgoAAyyyy...",
        "generateAudio": true,
        "seed": 67890,
        "sampleCount": 1
      }'
    ```
  </Tab>
  
  <Tab title="Ali Wanxiang">
    **1. Text-to-Video (Basic Example)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "wan2.5-t2v-preview",
        "prompt": "A kitten slowly opens its eyes, ears gently twitch, camera slowly pushes in",
        "duration": 5,
        "size": "1280*720",
        "smart_rewrite": true,
        "generate_audio": true
      }'
    ```
    
    **2. Text-to-Video (10 seconds, 1080p, with Random Seed)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "wan2.5-t2v-preview",
        "prompt": "A kitten slowly opens its eyes, ears gently twitch, camera slowly pushes in",
        "duration": 10,
        "size": "1920*1080",
        "smart_rewrite": false,
        "generate_audio": false,
        "seed": 123456
      }'
    ```
    
    **3. Image-to-Video (First Frame Mode)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "wan2.5-i2v-preview",
        "prompt": "Kitten slowly opens its eyes, ears gently twitch, camera slowly pushes in",
        "duration": 5,
        "resolution": "720p",
        "smart_rewrite": true,
        "generate_audio": true,
        "image": "data:image/png;base64,iVBORw0KGgoAAxxxx..."
      }'
    ```
    
    **4. Image-to-Video (with Custom Audio)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "wan2.5-i2v-preview",
        "prompt": "Kitten slowly opens its eyes, ears gently twitch, camera slowly pushes in",
        "duration": 10,
        "resolution": "1080p",
        "smart_rewrite": false,
        "generate_audio": false,
        "audio_url": "https://example.com/audio.mp3",
        "image": "data:image/png;base64,iVBORw0KGgoAAxxxx...",
        "seed": 789012
      }'
    ```
  </Tab>
  
  <Tab title="Doubao Seedance">
    **1. Text-to-Video (T2V, Basic Example)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "doubao-seedance-1-0-lite-t2v-250428",
        "prompt": "A cute kitten playing in a garden, sunny day",
        "content": [
          {
            "type": "text",
            "text": "A cute kitten playing in a garden, sunny day --ratio 16:9 --dur 5 --rs 720p --wm false"
          }
        ]
      }'
    ```
    
    **2. Text-to-Video (T2V, Full Parameters)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "doubao-seedance-1-0-lite-t2v-250428",
        "prompt": "A cute kitten playing in a garden, sunny day",
        "content": [
          {
            "type": "text",
            "text": "A cute kitten playing in a garden, sunny day --ratio 9:16 --dur 10 --rs 1080p --fps 30 --wm true --seed 12345"
          }
        ]
      }'
    ```
    
    **3. Image-to-Video (First Frame Mode)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "doubao-seedance-1-0-lite-i2v-250428",
        "prompt": "A girl opens her eyes and looks gently at the camera",
        "content": [
          {
            "type": "text",
            "text": "A girl opens her eyes and looks gently at the camera --ratio adaptive --dur 5 --rs 720p --wm false"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "data:image/png;base64,iVBORw0KGgoAAxxxx..."
            }
          }
        ]
      }'
    ```
    
    **4. Image-to-Video (First/Last Frame Mode, only lite-i2v supports)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "doubao-seedance-1-0-lite-i2v-250428",
        "prompt": "A blue-green jingwei bird transforms into human form",
        "content": [
          {
            "type": "text",
            "text": "A blue-green jingwei bird transforms into human form --rs 720p --dur 5 --fps 24 --cf false --wm false --seed 67890"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "data:image/png;base64,iVBORw0KGgoAAxxxx..."
            },
            "role": "first_frame"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "data:image/png;base64,iVBORw0KGgoAAyyyy..."
            },
            "role": "last_frame"
          }
        ]
      }'
    ```
    
    **5. Image-to-Video (Reference Image Mode, only lite-i2v supports)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "doubao-seedance-1-0-lite-i2v-250428",
        "prompt": "[图1] A boy wearing glasses and blue T-shirt and [图2] corgi dog, sitting on [图3] lawn, 3D cartoon style",
        "content": [
          {
            "type": "text",
            "text": "[图1] A boy wearing glasses and blue T-shirt and [图2] corgi dog, sitting on [图3] lawn, 3D cartoon style --rs 720p --dur 5 --ratio 16:9 --wm false"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "https://example.com/ref1.png"
            },
            "role": "reference_image"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "https://example.com/ref2.png"
            },
            "role": "reference_image"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "https://example.com/ref3.png"
            },
            "role": "reference_image"
          }
        ]
      }'
    ```
    
    **6. Pro Model (First Frame Mode)**
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "doubao-seedance-1-0-pro-250528",
        "prompt": "A girl opens her eyes and looks gently at the camera",
        "content": [
          {
            "type": "text",
            "text": "A girl opens her eyes and looks gently at the camera --ratio 16:9 --dur 5 --rs 1080p --wm false"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "data:image/png;base64,iVBORw0KGgoAAxxxx..."
            }
          }
        ]
      }'
    ```
  </Tab>
</Tabs>

#### Response Example

```json
{
  "task_id": "video_69095b4ce0048190893a01510c0c98b0",
  "status": "submitted",
  "format": "mp4"
}
```

## Request Parameters

<ParamField body="model" type="string" required>
  Model identifier, supported models and features:

  **Sora 2 Series**:
  - `sora-2` - Supports text-to-video, image-to-video, video-to-video (Remix mode)

  **Google Veo Series**:
  - `veo-3.0-fast-generate-001` - Text-to-video (first frame mode)
  - `veo-3.1-fast-generate-preview` - Text-to-video (first frame mode, first/last frame mode)

  **Ali Wanxiang Series**:
  - `wan2.5-t2v-preview` - Text-to-video
  - `wan2.5-i2v-preview` - Image-to-video (first frame mode)

  **Doubao Seedance Series**:
  - `doubao-seedance-1-0-lite-t2v-250428` - Text-to-video
  - `doubao-seedance-1-0-lite-i2v-250428` - Image-to-video (first frame mode, first/last frame mode, reference image mode)
  - `doubao-seedance-1-0-pro-250528` - Text-to-video (first frame mode)
</ParamField>

<ParamField body="prompt" type="string" required>
  Video generation prompt, describing scene actions and settings
</ParamField>

<ParamField body="image" type="string">
  Reference image for image-to-video (supports Base64 or URL format)
</ParamField>

<ParamField body="duration" type="integer" default="5">
  Video duration (seconds), different models support different durations
</ParamField>

<ParamField body="resolution" type="string" default="720p">
  Video resolution: `480p`, `720p`, `1080p`, `4k`
</ParamField>

<ParamField body="aspect_ratio" type="string" default="16:9">
  Aspect ratio: `16:9`, `9:16`, `1:1`, `4:3`, `3:4`, `21:9`, `adaptive` (adaptive, only supported by some models)
</ParamField>

## Model-Specific Parameters

Different models support different specific parameters. Below are detailed descriptions by model series:

<Tabs>
  <Tab title="Sora 2">
<ParamField body="seconds" type="string|integer" default="4">
  Video duration (seconds), supports: `4`, `8`, `12`
</ParamField>
<ParamField body="size" type="string" default="720x1280">
  Video resolution, supports: `720x1280` (portrait), `1280x720` (landscape)
</ParamField>
<ParamField body="input_reference" type="string">
  Reference image (supports URL or Base64 format), for image-to-video
</ParamField>
<ParamField body="remix_from_video_id" type="string">
  Remix mode: Regenerate based on existing video ID (must start with `video_`)
</ParamField>
  </Tab>
  
  <Tab title="Veo">
<ParamField body="durationSeconds" type="integer" default="4">
  Video duration (seconds), supports: `4`, `6`, `8`
</ParamField>
<ParamField body="aspectRatio" type="string" default="16:9">
  Aspect ratio, only supports: `16:9`, `9:16`
</ParamField>
<ParamField body="resolution" type="string" default="1080p">
  Resolution, supports: `720p`, `1080p`
</ParamField>
<ParamField body="fps" type="integer" default="24">
  Frame rate, default 24
</ParamField>
<ParamField body="image" type="string">
  First frame reference image (supports URL or Base64 format)
</ParamField>
<ParamField body="lastFrame" type="string">
  Last frame reference image (supports URL or Base64 format), only `veo-3.1` series supports
</ParamField>
<ParamField body="generateAudio" type="boolean" default="false">
  Whether to generate synchronized audio. Fast models ignore this parameter and always include audio
</ParamField>
<ParamField body="personGeneration" type="string" default="allow_all">
  Person generation strategy: `allow_all` (all ages), `allow_adult` (adults only), `dont_allow` (no persons)
</ParamField>
<ParamField body="addWatermark" type="boolean" default="false">
  Whether to add watermark
</ParamField>
<ParamField body="seed" type="integer">
  Random seed for reproducing results
</ParamField>
<ParamField body="sampleCount" type="integer" default="1">
  Number of videos to generate per request, range: `1-4`
</ParamField>
  </Tab>
  
  <Tab title="Ali Wanxiang">
<ParamField body="duration" type="integer" default="5">
  Video duration (seconds), supports: `5`, `10`
</ParamField>
<ParamField body="resolution" type="string" default="720p">
  Video resolution, supports: `480p`, `720p`, `1080p`
</ParamField>
<ParamField body="size" type="string">
  Video size (t2v mode only), format: `width*height`, e.g. `1280*720`
</ParamField>
<ParamField body="smart_rewrite" type="boolean" default="false">
  Whether to enable intelligent prompt expansion
</ParamField>
<ParamField body="generate_audio" type="boolean" default="false">
  Whether to generate synchronized audio with video
</ParamField>
<ParamField body="audio_url" type="string">
  Custom audio file URL (HTTPS format)
</ParamField>
<ParamField body="seed" type="integer">
  Random seed, range: `0-2147483647`
</ParamField>
  </Tab>
  
  <Tab title="Doubao Seedance">
<ParamField body="content" type="array" required>
  Content array, must include text and optional images. Parameters are controlled through special markers in text prompts:
  - `--rs` or `--resolution`: Resolution (`480p`, `720p`, `1080p`)
  - `--ratio`: Aspect ratio (`16:9`, `9:16`, `1:1`, `4:3`, `3:4`, `adaptive`, note that `doubao-seedance-1-0-lite-t2v-250428` does not support `adaptive`)
  - `--dur` or `--duration`: Duration (seconds, e.g. `5`, `10`)
  - `--fps` or `--framespersecond`: Frame rate (e.g. `24`, `30`)
  - `--seed`: Random seed
  - `--wm` or `--watermark`: Watermark toggle (`true`, `false`)
  - `--cf` or `--camerafixed`: Fixed camera (`true`, `false`, only lite models support)
  
  **content array format**:
  ```json
  [
    {
      "type": "text",
      "text": "Prompt content --ratio 16:9 --dur 5 --rs 720p --wm false"
    },
    {
      "type": "image_url",
      "image_url": {
        "url": "data:image/png;base64,..."
      },
      "role": "first_frame"  // Optional: first_frame, last_frame, reference_image
    }
  ]
  ```
</ParamField>
<ParamField body="prompt" type="string" required>
  Base prompt (without parameter markers), parameter markers will be automatically added to the text in the content array
</ParamField>
  </Tab>
</Tabs>

## Complete Examples

### Doubao Seedance Series

Doubao Seedance series models use a special parameter passing method: **all parameters are passed through special markers in the prompt**, and images are passed through the `content` array.

#### 1. Text-to-Video (T2V)

```bash
curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
  -H "Authorization: Bearer sk-xxxxxxxxxx" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "doubao-seedance-1-0-lite-t2v-250428",
    "prompt": "A cute kitten playing in a garden, sunny day",
    "content": [
      {
        "type": "text",
        "text": "A cute kitten playing in a garden, sunny day --ratio 16:9 --dur 5 --rs 720p --wm false"
      }
    ]
  }'
```

#### 2. Image-to-Video - First Frame Mode

```bash
curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
  -H "Authorization: Bearer sk-xxxxxxxxxx" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "doubao-seedance-1-0-lite-i2v-250428",
    "prompt": "A girl opens her eyes and looks gently at the camera",
    "content": [
      {
        "type": "text",
        "text": "A girl opens her eyes and looks gently at the camera --ratio adaptive --dur 5 --rs 720p --wm false"
      },
      {
        "type": "image_url",
        "image_url": {
          "url": "data:image/png;base64,iVBORw0KGgoAAxxxx..."
        }
      }
    ]
  }'
```

#### 3. Image-to-Video - First/Last Frame Mode (Only lite-i2v supports)

```bash
curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
  -H "Authorization: Bearer sk-xxxxxxxxxx" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "doubao-seedance-1-0-lite-i2v-250428",
    "prompt": "A blue-green jingwei bird transforms into human form",
    "content": [
      {
        "type": "text",
        "text": "A blue-green jingwei bird transforms into human form --rs 720p --dur 5 --cf false"
      },
      {
        "type": "image_url",
        "image_url": {
          "url": "data:image/png;base64,iVBORw0KGgoAAxxxx..."
        },
        "role": "first_frame"
      },
      {
        "type": "image_url",
        "image_url": {
          "url": "data:image/png;base64,iVBORw0KGgoAAyyyy..."
        },
        "role": "last_frame"
      }
    ]
  }'
```

#### 4. Image-to-Video - Reference Image Mode (Only lite-i2v supports)

```bash
curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
  -H "Authorization: Bearer sk-xxxxxxxxxx" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "doubao-seedance-1-0-lite-i2v-250428",
    "prompt": "[图1] A boy wearing glasses and blue T-shirt and [图2] corgi dog, sitting on [图3] lawn, 3D cartoon style",
    "content": [
      {
        "type": "text",
        "text": "[图1] A boy wearing glasses and blue T-shirt and [图2] corgi dog, sitting on [图3] lawn, 3D cartoon style --rs 720p --dur 5"
      },
      {
        "type": "image_url",
        "image_url": {
          "url": "https://example.com/ref1.png"
        },
        "role": "reference_image"
      },
      {
        "type": "image_url",
        "image_url": {
          "url": "https://example.com/ref2.png"
        },
        "role": "reference_image"
      },
      {
        "type": "image_url",
        "image_url": {
          "url": "https://example.com/ref3.png"
        },
        "role": "reference_image"
      }
    ]
  }'
```

**Important Notes**:
- All parameters must be passed through special markers in the prompt (e.g., `--ratio 16:9`)
- Images must be placed in the `content` array using `image_url` type
- First/last frame mode requires two images, marked with `role: "first_frame"` and `role: "last_frame"` respectively
- Reference image mode requires using `[图1]`, `[图2]` etc. in the prompt to reference images, with images marked `role: "reference_image"`
- `doubao-seedance-1-0-lite-t2v-250428` does not support image input and `adaptive` aspect ratio
- `doubao-seedance-1-0-pro-250528` only supports first frame mode

<Tabs>
  <Tab title="Sora 2 Complete Example">
    ### 1. Submit Video Generation Task
    
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "sora-2",
        "prompt": "A cute kitten playing in a garden, sunny day, warm scene",
        "seconds": "4",
        "size": "720x1280"
      }'
    ```
    
    **Response Example**:
    ```json
    {
      "task_id": "video_69095b4ce0048190893a01510c0c98b0",
      "status": "submitted",
      "format": "mp4"
    }
    ```
    
    ### 2. Poll Task Status
    
    ```bash
    curl -X GET "https://llm.ai-nebula.com/v1/video/generations/video_69095b4ce0048190893a01510c0c98b0" \
      -H "Authorization: Bearer sk-xxxxxxxxxx"
    ```
    
    **Task Status Description**:
    
    | Status | Description | Recommended Action |
    |--------|-------------|-------------------|
    | `queued` | Task queued, waiting for processing | Continue polling |
    | `in_progress` | Task processing | Continue polling |
    | `succeeded` | Task completed successfully | Download video |
    | `failed` | Task failed | Check failure reason |
    
    **Response Example (Queued)**:
    ```json
    {
      "task_id": "video_69095b4ce0048190893a01510c0c98b0",
      "status": "queued",
      "format": "mp4"
    }
    ```
    
    **Response Example (Processing)**:
    ```json
    {
      "task_id": "video_69095b4ce0048190893a01510c0c98b0",
      "status": "in_progress",
      "format": "mp4"
    }
    ```
    
    **Response Example (Completed)**:
    ```json
    {
      "task_id": "video_69095b4ce0048190893a01510c0c98b0",
      "status": "succeeded",
      "format": "mp4"
    }
    ```
    
    **Response Example (Failed)**:
    ```json
    {
      "task_id": "video_69095b4ce0048190893a01510c0c98b0",
      "status": "failed",
      "format": "mp4",
      "error": {
        "code": 400,
        "message": "Prompt contains inappropriate content"
      }
    }
    ```
    
    **Important Note**:
    - When task status is `queued` or `in_progress`, you need to poll regularly (recommended every 3-5 seconds)
    - When status becomes `succeeded`, you can use `task_id` as `videoId` to download the video
    - When status becomes `failed`, you can check the `error` field for failure reason
    
    ### 3. Download Video (Sora 2 Exclusive)
    
    Use the `task_id` returned after successful polling (as `videoId`) to download the video:
    
    ```bash
    curl -X GET "https://llm.ai-nebula.com/v1/video/generations/download?id=video_69095b4ce0048190893a01510c0c98b0" \
      -H "Authorization: Bearer sk-xxxxxxxxxx"
    ```
    
    **Note**: The value of the `id` parameter is the `task_id` returned after successful polling in step 2.
    
    **Response Example**:
    ```json
    {
      "success": true,
      "generation_id": "video_69095b4ce0048190893a01510c0c98b0",
      "task_id": "video_69095b4ce0048190893a01510c0c98b0",
      "format": "mp4",
      "size": 15728640,
      "base64": "AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAB...",
      "data_url": "data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAB..."
    }
    ```
    
    **Response Field Description**:
    
    | Field Name | Type | Description |
    |-----------|------|-------------|
    | `success` | boolean | Whether successful |
    | `generation_id` | string | Generation ID (same as videoId) |
    | `task_id` | string | Task ID |
    | `format` | string | Video format (fixed as `"mp4"`) |
    | `size` | number | Video file size (bytes) |
    | `base64` | string | Base64-encoded video data |
    | `data_url` | string | Video data in Data URL format, can be directly used in frontend `<video>` tag |
  </Tab>
  
  <Tab title="Veo Complete Example">
    ### 1. Submit Video Generation Task
    
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "veo-3.1-generate-preview",
        "prompt": "Aerial view of a sci-fi city at dawn, sunlight piercing through clouds",
        "durationSeconds": 8,
        "aspectRatio": "16:9",
        "resolution": "1080p",
        "generateAudio": true,
        "image": "https://example.com/start-frame.png",
        "lastFrame": "https://example.com/end-frame.png"
      }'
    ```
    
    **Response Example**:
    ```json
    {
      "task_id": "video_1234567890abcdef",
      "status": "submitted",
      "format": "mp4"
    }
    ```
    
    ### 2. Poll Task Status
    
    ```bash
    curl -X GET "https://llm.ai-nebula.com/v1/video/generations/video_1234567890abcdef" \
      -H "Authorization: Bearer sk-xxxxxxxxxx"
    ```
    
    **Response Example (Completed)**:
    ```json
    {
      "task_id": "video_1234567890abcdef",
      "status": "succeeded",
      "format": "mp4",
      "url": "https://nebula-ads.oss-cn-guangzhou.aliyuncs.com/2025/11/18/abc123/veo-demo-1.mp4"
    }
    ```
    
    **Note**: For Veo and Ali Wanxiang, when the task succeeds, the video URL is directly included in the response, no additional download step is needed.
  </Tab>
  
  <Tab title="Ali Wanxiang Complete Example">
    ### 1. Submit Video Generation Task
    
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "wan2.5-i2v-preview",
        "prompt": "A kitten slowly opens its eyes, ears gently twitch, camera slowly pushes in",
        "image": "https://example.com/cat.jpg",
        "duration": 5,
        "resolution": "720p",
        "smart_rewrite": true,
        "generate_audio": true
      }'
    ```
    
    **Response Example**:
    ```json
    {
      "task_id": "ae8eb420-8aa6-440a-8eb8-1d1afe8d5e97",
      "status": "submitted",
      "format": "mp4"
    }
    ```
    
    ### 2. Poll Task Status
    
    ```bash
    curl -X GET "https://llm.ai-nebula.com/v1/video/generations/ae8eb420-8aa6-440a-8eb8-1d1afe8d5e97" \
      -H "Authorization: Bearer sk-xxxxxxxxxx"
    ```
    
    **Response Example (Completed)**:
    ```json
    {
      "task_id": "ae8eb420-8aa6-440a-8eb8-1d1afe8d5e97",
      "status": "succeeded",
      "format": "mp4",
      "url": "https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/.../video.mp4?Expires=..."
    }
    ```
  </Tab>
  
  <Tab title="Doubao Seedance Complete Example">
    ### 1. Text-to-Video (T2V)
    
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "doubao-seedance-1-0-pro-250528",
        "prompt": "Multiple shots. A detective enters a dimly lit room. He examines clues on the table, picks up an item. Camera turns to him thinking. --ratio 16:9 --dur 5",
        "metadata": {
          "content": [
            {
              "type": "text",
              "text": "Multiple shots. A detective enters a dimly lit room. He examines clues on the table, picks up an item. Camera turns to him thinking. --ratio 16:9 --dur 5"
            }
          ]
        }
      }'
    ```
    
    ### 2. Image-to-Video - First Frame Mode (I2V)
    
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "doubao-seedance-1-0-pro-250528",
        "prompt": "A girl holding a fox, the girl opens her eyes, looks gently at the camera, the fox hugs friendly, camera slowly pulls out, the girl'\''s hair is blown by the wind --ratio adaptive --dur 5",
        "metadata": {
          "content": [
            {
              "type": "text",
              "text": "A girl holding a fox, the girl opens her eyes, looks gently at the camera, the fox hugs friendly, camera slowly pulls out, the girl'\''s hair is blown by the wind --ratio adaptive --dur 5"
            },
            {
              "type": "image_url",
              "image_url": {
                "url": "https://example.com/first-frame.png"
              }
            }
          ]
        }
      }'
    ```
    
    ### 3. Image-to-Video - First/Last Frame Mode (Only lite-i2v supports)
    
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "doubao-seedance-1-0-lite-i2v-250428",
        "prompt": "A blue-green jingwei bird transforms into human form --rs 720p --dur 5 --cf false",
        "metadata": {
          "content": [
            {
              "type": "text",
              "text": "A blue-green jingwei bird transforms into human form --rs 720p --dur 5 --cf false"
            },
            {
              "type": "image_url",
              "image_url": {
                "url": "https://example.com/first-frame.png"
              },
              "role": "first_frame"
            },
            {
              "type": "image_url",
              "image_url": {
                "url": "https://example.com/last-frame.png"
              },
              "role": "last_frame"
            }
          ]
        }
      }'
    ```
    
    ### 4. Image-to-Video - Reference Image Mode (Only lite-i2v supports)
    
    ```bash
    curl -X POST "https://llm.ai-nebula.com/v1/video/generations" \
      -H "Authorization: Bearer sk-xxxxxxxxxx" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "doubao-seedance-1-0-lite-i2v-250428",
        "prompt": "[图1] A boy wearing glasses and blue T-shirt and [图2] corgi dog, sitting on [图3] lawn, 3D cartoon style",
        "metadata": {
          "content": [
            {
              "type": "text",
              "text": "[图1] A boy wearing glasses and blue T-shirt and [图2] corgi dog, sitting on [图3] lawn, 3D cartoon style"
            },
            {
              "type": "image_url",
              "image_url": {
                "url": "https://example.com/ref1.png"
              },
              "role": "reference_image"
            },
            {
              "type": "image_url",
              "image_url": {
                "url": "https://example.com/ref2.png"
              },
              "role": "reference_image"
            },
            {
              "type": "image_url",
              "image_url": {
                "url": "https://example.com/ref3.png"
              },
              "role": "reference_image"
            }
          ]
        }
      }'
    ```
    
    **Response Example**:
    ```json
    {
      "task_id": "cgt-2025123456-abcd",
      "status": "submitted",
      "format": "mp4"
    }
    ```
    
    ### 5. Poll Task Status
    
    ```bash
    curl -X GET "https://llm.ai-nebula.com/v1/video/generations/cgt-2025123456-abcd" \
      -H "Authorization: Bearer sk-xxxxxxxxxx"
    ```
    
    **Response Example (Completed)**:
    ```json
    {
      "task_id": "cgt-2025123456-abcd",
      "status": "succeeded",
      "format": "mp4",
      "url": "https://ark-content-generation-cn-beijing.tos-cn-beijing.volces.com/.../video.mp4?X-Tos-Algorithm=..."
    }
    ```
  </Tab>
</Tabs>

## Supported Models

### Sora 2 Series

**Model Name**: `sora-2`

**Core Capabilities**:
- ✅ Text-to-video (pure text description generates video)
- ✅ Image-to-video (single image + text generates video)
- ✅ Remix mode (regenerate based on existing video)

**Supported Parameters**:
- `seconds`: Video duration (4, 8, 12 seconds), default 4 seconds
- `size`: Video resolution (`720x1280` portrait, `1280x720` landscape), default `720x1280`
- `width` / `height`: Video width and height (automatically converted to `size` parameter)
- `input_reference`: Reference image (supports URL or Base64 format), for image-to-video
- `remix_from_video_id`: Remix mode, regenerate based on existing video ID (must start with `video_`)

**Notes**:
- Video generation is an asynchronous task, need to first submit task to get `task_id`, then poll task status
- When task status is `succeeded`, use `task_id` as `videoId` to call download interface to get video
- Download interface returns Base64-encoded video data, can be directly used for frontend playback or saved as file
- Image input formats support JPEG, PNG, image size must exactly match `size` parameter for image-to-video

### Veo Series

**Model Names**: `veo-3.1-generate-preview`, `veo-3.1-fast-generate-preview`, `veo-3.0-generate-preview`, `veo-3.0-fast-generate-001`

**Core Capabilities**:
- ✅ Text-to-video
- ✅ Image-to-video (supports first frame and last frame constraints)
- ✅ Audio generation

**Supported Parameters**:
- `durationSeconds`: Video duration (4, 6, 8 seconds)
- `aspectRatio`: Aspect ratio (16:9, 9:16)
- `resolution`: Resolution (720p, 1080p)
- `generateAudio`: Whether to generate audio
- `image`: First frame reference image
- `lastFrame`: Last frame reference image
- `seed`: Random seed

### Ali Wanxiang Series

**Model Name**: `wan2.5-i2v-preview`

**Core Capabilities**:
- ✅ Image-to-video
- ✅ Supports custom audio upload
- ✅ Intelligent prompt expansion
- ✅ Auto-generate synchronized audio with video

**Supported Parameters**:
- `duration`: Video duration (5, 10 seconds)
- `resolution`: Video resolution (480p, 720p, 1080p)
- `smart_rewrite`: Whether to enable intelligent prompt expansion
- `generate_audio`: Whether to generate synchronized audio with video
- `audio_url`: Custom audio file URL
- `seed`: Random seed

### Doubao Seedance Series

**Model Names**:
- `doubao-seedance-1-0-pro-250528` - Pro version, supports text-to-video and image-to-video (first frame mode)
- `doubao-seedance-1-0-lite-t2v-250428` - Lite version text-to-video
- `doubao-seedance-1-0-lite-i2v-250428` - Lite version image-to-video, supports first frame, first/last frame, reference image three modes
- `doubao-seaweed-1-0-t2v-250428` - Seaweed version text-to-video
- `wan2-1-14b-i2v-250417` - Wanxiang version image-to-video
- `wan2-1-14b-flf2v-250417` - Wanxiang version first/last frame generation

**Core Capabilities**:
- ✅ Text-to-video (T2V)
- ✅ Image-to-video - First frame mode (I2V)
- ✅ Image-to-video - First/last frame mode (only `doubao-seedance-1-0-lite-i2v-250428` and `wan2-1-14b-flf2v-250417` support)
- ✅ Image-to-video - Reference image mode (only `doubao-seedance-1-0-lite-i2v-250428` supports)

**Supported Parameters** (controlled through special markers in text prompts):
- `--rs` / `--resolution`: Resolution (`480p`, `720p`, `1080p`)
- `--ratio`: Aspect ratio (`16:9`, `9:16`, `1:1`, `4:3`, `3:4`, `adaptive`)
- `--dur` / `--duration`: Duration (seconds, e.g. `5`, `10`)
- `--fps` / `--framespersecond`: Frame rate (e.g. `24`, `30`)
- `--seed`: Random seed
- `--wm` / `--watermark`: Watermark toggle (`true`, `false`)
- `--cf` / `--camerafixed`: Fixed camera (`true`, `false`, only lite models support)

**Image Input Format**:
- In `metadata.content` array, image items can be marked via `role` field:
  - `first_frame`: First frame image
  - `last_frame`: Last frame image
  - `reference_image`: Reference image (use `[图N]` in prompt to reference)

**Notes**:
- `doubao-seedance-1-0-lite-t2v-250428` only supports text-to-video, does not support image input
- Reference image mode of `doubao-seedance-1-0-lite-i2v-250428` does not support `1080p` resolution
- `doubao-seedance-1-0-lite-t2v-250428` does not support `adaptive` aspect ratio

## Best Practices

### Polling Strategy

<Tabs>
  <Tab title="Python Polling Example">
    ```python
    import requests
    import time
    
    def poll_task_status(task_id, api_key, max_wait_time=300):
        """Poll task status until completion"""
        url = f"https://llm.ai-nebula.com/v1/video/generations/{task_id}"
        headers = {"Authorization": f"Bearer {api_key}"}
        
        start_time = time.time()
        while True:
            response = requests.get(url, headers=headers)
            data = response.json()
            status = data.get("status")
            
            print(f"Current status: {status}")
            
            if status == "succeeded":
                video_url = data.get("url")
                print(f"✅ Task completed! Video URL: {video_url}")
                return video_url
            elif status == "failed":
                error_msg = data.get("metadata", {}).get("output", {}).get("message", "Unknown error")
                print(f"❌ Task failed: {error_msg}")
                return None
            
            # Check timeout
            if time.time() - start_time > max_wait_time:
                print("⏰ Wait timeout")
                return None
            
            # Wait 5 seconds before querying again
            time.sleep(5)
    ```
  </Tab>
  
  <Tab title="JavaScript Polling Example">
    ```javascript
    async function pollTaskStatus(taskId, apiKey, maxWaitTime = 300000) {
      const url = `https://llm.ai-nebula.com/v1/video/generations/${taskId}`;
      const headers = { 'Authorization': `Bearer ${apiKey}` };
      
      const startTime = Date.now();
      
      while (true) {
        const response = await fetch(url, { headers });
        const data = await response.json();
        const status = data.status;
        
        console.log(`Current status: ${status}`);
        
        if (status === 'succeeded') {
          const videoUrl = data.url;
          console.log(`✅ Task completed! Video URL: ${videoUrl}`);
          return videoUrl;
        } else if (status === 'failed') {
          const errorMsg = data.metadata?.output?.message || 'Unknown error';
          console.error(`❌ Task failed: ${errorMsg}`);
          throw new Error(errorMsg);
        }
        
        // Check timeout
        if (Date.now() - startTime > maxWaitTime) {
          throw new Error('Wait timeout');
        }
        
        // Wait 5 seconds before querying again
        await new Promise(resolve => setTimeout(resolve, 5000));
      }
    }
    ```
  </Tab>
</Tabs>

## FAQ

<Tabs>
  <Tab title="General Questions">
    <AccordionGroup>
      <Accordion title="How long does video generation take?">
        Usually takes 1-5 minutes, depending on video duration, resolution, and server load.
      </Accordion>
      
      <Accordion title="How long are generated videos valid?">
        Video URLs are valid for approximately 24 hours. It is recommended to download and save immediately after receiving the response.
      </Accordion>
      
      <Accordion title="What image input formats are supported?">
        Supports PNG, JPEG, JPG, WEBP formats, maximum file size 10MB.
      </Accordion>
    </AccordionGroup>
  </Tab>
  
  <Tab title="Sora 2">
    <AccordionGroup>
      <Accordion title="Why does Sora 2 require an additional download step?">
        Sora 2 video files are stored in a separate storage service. After task success, it returns a signed temporary URL that requires additional download.
      </Accordion>
      
      <Accordion title="What video durations are supported?">
        Supports 4 seconds, 8 seconds, and 12 seconds.
      </Accordion>
    </AccordionGroup>
  </Tab>
  
  <Tab title="Veo">
    <AccordionGroup>
      <Accordion title="What video durations are supported?">
        Supports 4 seconds, 6 seconds, and 8 seconds.
      </Accordion>
      
      <Accordion title="How to generate audio?">
        Set `generateAudio: true` parameter, system will automatically generate synchronized audio with video.
      </Accordion>
    </AccordionGroup>
  </Tab>
  
  <Tab title="Ali Wanxiang">
    <AccordionGroup>
      <Accordion title="What video durations are supported?">
        Supports 5 seconds and 10 seconds.
      </Accordion>
      
      <Accordion title="How to upload custom audio?">
        Provide `audio_url` parameter, pointing to a publicly accessible audio file URL.
      </Accordion>
    </AccordionGroup>
  </Tab>
  
  <Tab title="Doubao Seedance">
    <AccordionGroup>
      <Accordion title="How to set video parameters?">
        Doubao Seedance model parameters are controlled through special markers in text prompts, for example:
        `--rs 720p --ratio 16:9 --dur 5 --fps 24 --seed 12345`
      </Accordion>
      
      <Accordion title="What image-to-video modes are supported?">
        - **First Frame Mode**: Supported by all models that support image-to-video
        - **First/Last Frame Mode**: Only `doubao-seedance-1-0-lite-i2v-250428` and `wan2-1-14b-flf2v-250417` support
        - **Reference Image Mode**: Only `doubao-seedance-1-0-lite-i2v-250428` supports, can use `[图1]`, `[图2]` etc. in prompt to reference multiple reference images
      </Accordion>
      
      <Accordion title="How to configure callback notification?">
        Set `callback_url` field in `metadata`, task status changes will automatically push results to that URL.
      </Accordion>
      
      <Accordion title="What aspect ratios are supported?">
        Most models support `16:9`, `9:16`, `1:1`, `4:3`, `3:4`, `adaptive` (adaptive). Note that `doubao-seedance-1-0-lite-t2v-250428` does not support `adaptive`.
      </Accordion>
    </AccordionGroup>
  </Tab>
</Tabs>

## Related Resources

<Columns cols={2}>
  <Card title="Image Generation" icon="image" href="/en/api-reference/endpoint/image-generation">
    View image generation API documentation
  </Card>
  <Card title="Model List" icon="list" href="/en/api-reference/models">
    View all supported model information
  </Card>
</Columns>
